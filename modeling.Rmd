---
title: "Predictive Modeling"
output: html_notebook
---

This notebook provides the code for clustering, principal component analysis and classification trees/random forest.

Our proposed method first split the 20 samples into training (n=15) and testing (n=5) set. We first trained a preliminary classifier on the training set with scanner data that categorized the samples into three classes (good, bad and uncertain). We made predictions on the test data, then the test samples that were classified as "uncertain" were taken to a more refined classifier trained with high resolution VR measurements. The "uncertain" samples were then predicted again to either "good" or "bad". 

## Labeling the data with ground truth
```{r,warning=FALSE}
qualitydf<-read.csv("qualitydf.csv",header = T)
```

```{r}
# clustering with profile resid and roughness to give the samples a ground "truth"
set.seed(4747)
library(ggplot2)
quality_cluster<-kmeans(qualitydf[,c(1,2)],2)

# label the cluster
cluster<-quality_cluster$cluster
for(i in 1:length(cluster)){
  cluster[i]<-ifelse(cluster[i]==2,"bad","good")
}

# factorize the cluster label and create a big data frame
ground_truth<-as.factor(cluster)
bigdf<-cbind(qualitydf,ground_truth)

# plot the clustering result
ggplot(bigdf,aes(x=texture,y=profile_resid,shape=as.factor(height),color=cluster))+geom_point()+coord_flip()+theme_classic()
```



## Scanner classifier only
```{r,warning=FALSE}
# read in the scanner data
library(readr)
folder <- "~/Documents/School/DIMACS REU/measurements/scanner-data/"
file_list <- list.files(path = folder, pattern = "*.obj")

scannerdf<-data.frame()
for (i in 1:length(file_list)){
  scanner<-read_delim(paste(folder, file_list[i],sep='')," ", escape_double = FALSE, col_names = FALSE,
    trim_ws = TRUE, skip = 3)[,-1]
  name<-paste("scanner-",substr(file_list[i],start=1,stop=nchar(file_list[i])-4),sep ='')
  assign(name, scanner) 
  
  X<-scanner$X2
  Y<-scanner$X3
  Z<-scanner$X4
  
  # trim X, Y and Z that are out of range
  xTrim<-which(abs(X)<=32)
  Y<-Y[xTrim]
  Z<-Z[xTrim]
  X<-X[xTrim]

  yTrim<-which(abs(Y)<=32)
  Z<-Z[yTrim]
  X<-X[yTrim]
  Y<-Y[yTrim]
  
  # put Z of each sample into the rows of the df
  scannerdf<-rbind(scannerdf,Z)
}

# omit NAs with zero
scannerdf[is.na(scannerdf)]<-0
dim(scannerdf)
```

```{r}
# split into train and test by 3:1
# sample 3 from good and 3 from bad
set.seed(4747)
goodind<-sample(which(bigdf$ground_truth=="good"),3,replace=FALSE)
badind<-sample(which(bigdf$ground_truth=="bad"),3,replace=FALSE)
testind<-c(goodind,badind)
bigdf[testind,]
```

```{r}
# extract pca from scanner training set
scanner_mat_train<-as.matrix(scannerdf)[-testind,]
scanner_pca_train<-prcomp(scanner_mat_train,center=TRUE)$x[,1:4]
colnames(scanner_pca_train)<-c("scanner_PC1","scanner_PC2","scanner_PC3","scanner_PC4")

scanner_mat_test<-as.matrix(scannerdf)[testind,]
scanner_pca_test<-prcomp(scanner_mat_test,center=TRUE)$x[,1:4]
colnames(scanner_pca_test)<-c("scanner_PC1","scanner_PC2","scanner_PC3","scanner_PC4")
```


```{r}
require(dplyr)
# create the training data frame
train_df<-data.frame(cbind(scanner_pca_train,bigdf[-testind,][,-c(1,2)]))
test_df<-data.frame(cbind(scanner_pca_test,bigdf[testind,][,-c(1,2)]))
```


### Random Forest
```{r}
# using only scanner data and pca
library(Metrics)
control<-trainControl(method="cv",number=3,summaryFunction=twoClassSummary,classProbs = TRUE)
seed <- 47
metric <- "ROC"
set.seed(seed)
mtry <- 1:7 
tunegrid <- expand.grid(.mtry=mtry)
rf_pca <- train(cluster~., data=train_df, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control,preProcess = c("scale", "center"))
rf_pca
confusionMatrix(predict(rf_pca,test_df),test_df$cluster)
```

```{r}
a<-varImp(rf_pca)
head(rownames(a$importance),3)
```


## Proposed Method using both scanner and high resolution

### Training the first classifier
```{r}
# split into train and test with balanced
new_train<-qualitydf[-testind,]
new_test<-qualitydf[testind,]
# label the cluster
set.seed(47)
clustering<-kmeans(new_train[,c(1,2)],3)
cluster<-clustering$cluster
for(i in 1:length(cluster)){
  cluster[i]<-ifelse(cluster[i]==3,"good",ifelse(cluster[i]==2,"uncertain","bad"))
}
cluster<-as.factor(cluster)
new_train<-cbind(new_train,cluster)


# plot the clustering result
ggplot(new_train,aes(x=texture,y=profile_resid,shape=as.factor(height),color=cluster))+geom_point()+coord_flip()+theme_classic()
```

```{r}
# multiclass summary function

library(compiler)
multiClassSummary <- cmpfun(function (data, lev = NULL, model = NULL){

#Load Libraries
require(Metrics)
require(caret)

#Check data
if (!all(levels(data[, "pred"]) == levels(data[, "obs"]))) 
stop("levels of observed and predicted data do not match")

#Calculate custom one-vs-all stats for each class
prob_stats <- lapply(levels(data[, "pred"]), function(class){

#Grab one-vs-all data for the class
pred <- ifelse(data[, "pred"] == class, 1, 0)
obs <- ifelse(data[, "obs"] == class, 1, 0)
prob <- data[,class]

#Calculate one-vs-all AUC and logLoss and return
cap_prob <- pmin(pmax(prob, .000001), .999999)
prob_stats <- c(auc(obs, prob), logLoss(obs, cap_prob))
names(prob_stats) <- c('ROC', 'logLoss')
return(prob_stats) 
})
prob_stats <- do.call(rbind, prob_stats)
rownames(prob_stats) <- paste('Class:', levels(data[, "pred"]))

#Calculate confusion matrix-based statistics
CM <- confusionMatrix(data[, "pred"], data[, "obs"])

#Aggregate and average class-wise stats
#Todo: add weights
class_stats <- cbind(CM$byClass, prob_stats)
class_stats <- colMeans(class_stats)

#Aggregate overall stats
overall_stats <- c(CM$overall)

#Combine overall with class-wise stats and remove some stats we don't want 
stats <- c(overall_stats, class_stats)
stats <- stats[! names(stats) %in% c('AccuracyNull', 
'Prevalence', 'Detection Prevalence')]

#Clean names and return
names(stats) <- gsub('[[:blank:]]+', '_', names(stats))
return(stats)
})
```

```{r} 
library(Metrics)
scanner_train_df<-data.frame(cbind(scanner_pca_train,new_train[,-c(1,2)]))
scanner_test_df<-data.frame(cbind(scanner_pca_test,new_test[,-c(1,2)]))

control <- trainControl(method="cv",number=3,sampling = "up",summaryFunction=multiClassSummary,classProbs = TRUE)
seed <- 47
metric <- "ROC"
set.seed(seed)
mtry <- 1:7
tunegrid <- expand.grid(.mtry=mtry)
rf_scanner <- train(cluster~., data=scanner_train_df, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control,preProcess = c("scale", "center"))
rf_scanner
predict(rf_scanner,scanner_test_df)
bigdf[testind,]$cluster
```

### Training the second classifier
```{r}
# read in the VR high resolution measurement matrices 
folder <- "measurements/matrix/"
file_list <- list.files(path = folder, pattern = "*.csv")

mat_pca<-matrix(0,nrow=length(file_list),ncol=1520*1628)
namelst<-list()
for (i in 1:length(file_list)){
    df<- read.csv(paste(folder, file_list[i],sep=''),header=F,skip=23)
    df[is.na(df)]<-0
    #imputedf<-DMwR::knnImputation(df,k=5)
    name<-substr(file_list[i],start=11,stop=nchar(file_list[i])-17)
    namelst<-c(namelst,name)
    if (dim(df)[2]>1628){      # fix a minor issue where one matrix is reversed
      df<-df[1:1520,1:1628]
    }
    if (dim(df)[2]==1520){
      df<-t(df)
    }
    assign(name, df) 
    mat_pca[i,]<-as.vector(as.matrix(df))
}
length(file_list)
dim(mat_pca)
```

```{r}
# export the matrices for matlab umpca code
trainind<-seq(1,20,by=1)[-testind]
for (i in trainind){
  mat<-matrix(mat_pca[i,],1520,1628);
  write.csv(mat,paste("umpca_reconstruction/matrices/train/",namelst[i],".csv",sep=''))
}

for (i in testind){
  mat<-matrix(mat_pca[i,],1520,1628);
  write.csv(mat,paste("umpca_reconstruction/matrices/test/",namelst[i],".csv",sep=''))
}
```

```{r}
# load the umpca components from matlab
newfea_train<-read.csv("umpca_reconstruction/newfea_train.csv",header=FALSE)
num<-1:dim(newfea_train)[2]
names(newfea_train)<-paste("MPC",num,sep='')

newfea_test<-read.csv("umpca_reconstruction/newfea_test.csv",header=FALSE)
num<-1:dim(newfea_test)[2]
names(newfea_test)<-paste("MPC",num,sep='')
```

```{r}
# cluster the training samples into 2 classes
set.seed(47)
second_cluster<-kmeans(qualitydf[-testind,][,c(1,2)],2)

# label the cluster
cluster<-second_cluster$cluster
for(i in 1:length(cluster)){
  cluster[i]<-ifelse(cluster[i]==2,"good","bad")
}
cluster<-as.factor(cluster)
vr_df<-cbind(qualitydf[-testind,],cluster)
```

```{r}
# run a pca on VR high resolution data
vr_pca_train<-prcomp(mat_pca[-testind,],center = TRUE)$x[,1:4]
vr_pca_test<-prcomp(mat_pca[testind,],center = TRUE)$x[,1:4]
```

```{r,include=FALSE}
# create the umpca training data frame
umpca_train_df<-data.frame(cbind(vr_df,newfea_train))[,-c(1,2)]
umpca_test_df<-data.frame(cbind(new_test,newfea_test))[,-c(1,2)]
```

```{r}
# rf with pca
vr_train_df<-data.frame(cbind(vr_pca_train,vr_df[,-c(1,2)]))
vr_test_df<-data.frame(cbind(vr_pca_test,new_test[,-c(1,2)]))

#control<-trainControl(method="cv",number=3,sampling = "up",summaryFunction=twoClassSummary,classProbs = TRUE)
seed <- 47
#metric <- "ROC"
set.seed(seed)
mtry <- 1:7
tunegrid <- expand.grid(.mtry=mtry)
rf_vr <- train(cluster~., data=vr_train_df, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control,preProcess = c("scale", "center"))
rf_vr
confusionMatrix(predict(rf_vr,vr_test_df),bigdf[testind,]$ground_truth)
```

```{r}
# rf with umpca
#control<-trainControl(method="cv",number=3,sampling = "up",summaryFunction=twoClassSummary,classProbs = TRUE)
control<-trainControl(method="oob")
seed <- 47
metric <- "Accuracy"
set.seed(seed)
mtry <- 1:7
tunegrid <- expand.grid(.mtry=mtry)
rf_vr_umpca <- train(cluster~., data=umpca_train_df, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control,preProcess = c("scale", "center"))
rf_vr_umpca
confusionMatrix(predict(rf_vr_umpca,umpca_test_df),bigdf[testind,]$ground_truth)
```
